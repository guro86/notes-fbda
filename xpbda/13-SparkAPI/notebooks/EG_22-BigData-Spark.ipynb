{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Big Data: Spark Exercise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: RDDs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, import the relevant pyspark modules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": [
     "solution"
    ]
   },
   "outputs": [],
   "source": [
    "from pyspark import SparkConf, SparkContext"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, create an instance of Spark context handler."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": [
     "solution"
    ]
   },
   "outputs": [],
   "source": [
    "conf = SparkConf().setMaster(\"local\").setAppName(\"SparkExample\")\n",
    "sc = SparkContext(conf = conf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word Count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Count the number of distinct words in `columns.csv` using pyspark.\n",
    "2. Display the top 10 most frequent words\n",
    "\n",
    "Hints:\n",
    "* You need to read the file into an RDD object. \n",
    "* **Recall**: an RDD file is a collection of lines.\n",
    "\n",
    "\n",
    "* We don't want a collection of lines, we want a collection of words. \n",
    "* **Recall**: The Python string method .split(), and the RDD' .flatMap() transformation, may be useful.\n",
    "\n",
    "\n",
    "* You can use .countByValue() on the RDD to count the entries.\n",
    "* You can call `sorted()` on a dict with a function to provide the value to sort on\n",
    "\n",
    "\n",
    "\n",
    "* You want most frequent *words*, so normalize the input (ie., ignore case, ignore punctuation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "tags": [
     "solution"
    ]
   },
   "outputs": [],
   "source": [
    "# read file\n",
    "poem = sc.textFile('columns.csv')\n",
    "\n",
    "# turn a collection of lines into a collection of words\n",
    "words = poem.flatMap(lambda line : line.strip().replace('\"', '').lower().split())\n",
    "\n",
    "# count the number of words\n",
    "freq = words.countByValue()\n",
    "\n",
    "top = sorted(results, key=lambda k : freq[k], reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "tags": [
     "solution"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i', 'to', 'of', 'and', 'my', 'the', 'in', 'always', 'a', 'am']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "tags": [
     "solution"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{85: 'i',\n",
       " 25: 'to',\n",
       " 16: 'of',\n",
       " 14: 'my',\n",
       " 13: 'the',\n",
       " 12: 'in',\n",
       " 11: 'always',\n",
       " 9: 'am'}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "{freq[w]: w for w in top[:10]}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DataFrames"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Movies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The \"ml-100k\" folder contains 100,000 movie ratings given by 943 users on 1682 movies.\n",
    "\n",
    "The description of the data set is given in ml-100k/README.  \n",
    "\n",
    "\n",
    "The main dataset containing the ratings is \"u.data\", which is a space separated value (SSV) file with columns:\n",
    "1. user id\n",
    "2. movie id\n",
    "3. rating\n",
    "4. timestamp\n",
    "\n",
    "The film titles are contained in \"u.item\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question \n",
    "\n",
    "Find the top five most popular movies. \n",
    "\n",
    "These are **not** necessarily the highest rated ones, but the movies most frequently rated by the users.\n",
    "\n",
    "HINTS:\n",
    "* groupBy().count() to get the number of ratings for each movie\n",
    "* .orderBy() to sort the count column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import StructField, StructType, StringType, ShortType, LongType"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Define `spark` using `SparkSession`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "tags": [
     "solution"
    ]
   },
   "outputs": [],
   "source": [
    "spark = (\n",
    "SparkSession.builder\n",
    "    .master(\"local\")\n",
    "    .appName(\"Movies\")\n",
    "    .getOrCreate()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* `spark.read` the  `u.data` file\n",
    "\n",
    "HINT:\n",
    "* You will need to define your own schema: \n",
    "    * \"UserID\" will be a `LongType` \n",
    "    * \"MoveID\" will be a `LongType()`\n",
    "    * \"Rating\" will be a `ShortType()`\n",
    "    * \"Time\" will be a `LongType` \n",
    "    \n",
    "    \n",
    "    \n",
    "* Add the option `\"delimiter\"`, `\"\\t\"`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "tags": [
     "solution"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------+------+---------+\n",
      "|UserID|MovieID|Rating|     Time|\n",
      "+------+-------+------+---------+\n",
      "|   196|    242|     3|881250949|\n",
      "|   186|    302|     3|891717742|\n",
      "|    22|    377|     1|878887116|\n",
      "+------+-------+------+---------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "schema_user = StructType([\n",
    "  StructField(\"UserID\", LongType()),\n",
    "  StructField(\"MovieID\", LongType()),\n",
    "  StructField(\"Rating\", ShortType()),\n",
    "  StructField(\"Time\", LongType()),\n",
    "])\n",
    "\n",
    "dfu = (\n",
    "spark\n",
    "    .read\n",
    "    .schema(schema_user)\n",
    "    .option(\"header\", \"false\")\n",
    "    .option(\"delimiter\", \"\\t\")\n",
    "    .csv(\"ml-100k/u.data\")\n",
    ")\n",
    "\n",
    "dfu.show(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Read in `u.items`\n",
    "\n",
    "HINT:\n",
    "* You will need to define your own schema: \n",
    "    * \"MovieID\" will be a `LongType` \n",
    "    * \"Title\" will be a `StringType()`\n",
    "    \n",
    "    \n",
    "* Add the option `\"delimiter\"`, `\"|\"`\n",
    "\n",
    "\n",
    "* (You only need the first two columns for this problem, so that schema is complete)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "tags": [
     "solution"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----------------+\n",
      "|MovieID|            Title|\n",
      "+-------+-----------------+\n",
      "|      1| Toy Story (1995)|\n",
      "|      2| GoldenEye (1995)|\n",
      "|      3|Four Rooms (1995)|\n",
      "+-------+-----------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "schema_item = StructType([\n",
    "  StructField(\"MovieID\", LongType()),\n",
    "  StructField(\"Title\", StringType()),\n",
    "])\n",
    "\n",
    "dfi = (\n",
    "spark\n",
    "    .read\n",
    "    .schema(schema_item)\n",
    "    .option(\"header\", \"false\")\n",
    "    .option(\"delimiter\", \"|\")\n",
    "    .csv(\"ml-100k/u.item\")\n",
    ")\n",
    "\n",
    "dfi.show(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Group, Count and Order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "scrolled": true,
    "tags": [
     "solution"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----+\n",
      "|MovieID|count|\n",
      "+-------+-----+\n",
      "|     50|  583|\n",
      "|    258|  509|\n",
      "|    100|  508|\n",
      "|    181|  507|\n",
      "|    294|  485|\n",
      "|    286|  481|\n",
      "|    288|  478|\n",
      "|      1|  452|\n",
      "|    300|  431|\n",
      "|    121|  429|\n",
      "+-------+-----+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "results = dfu.groupby('MovieID').count().orderBy('count', ascending=0)\n",
    "results.show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "EXTRA:\n",
    "* Join your results to your items data frame\n",
    "\n",
    "HINT:\n",
    "* The join condition is `results['MovieID'] == dfi['MovieID']`\n",
    "* You can `.select` columns to tidy up the join"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "tags": [
     "solution"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+\n",
      "|               Title|count|\n",
      "+--------------------+-----+\n",
      "|    Star Wars (1977)|  583|\n",
      "|      Contact (1997)|  509|\n",
      "|        Fargo (1996)|  508|\n",
      "|Return of the Jed...|  507|\n",
      "|    Liar Liar (1997)|  485|\n",
      "|English Patient, ...|  481|\n",
      "|       Scream (1996)|  478|\n",
      "|    Toy Story (1995)|  452|\n",
      "|Air Force One (1997)|  431|\n",
      "|Independence Day ...|  429|\n",
      "|Raiders of the Lo...|  420|\n",
      "|Godfather, The (1...|  413|\n",
      "| Pulp Fiction (1994)|  394|\n",
      "|Twelve Monkeys (1...|  392|\n",
      "|Silence of the La...|  390|\n",
      "|Jerry Maguire (1996)|  384|\n",
      "|    Rock, The (1996)|  378|\n",
      "|Empire Strikes Ba...|  367|\n",
      "|Star Trek: First ...|  365|\n",
      "|Back to the Futur...|  350|\n",
      "+--------------------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "(results\n",
    "    .join(dfi, results['MovieID'] == dfi['MovieID'])\n",
    "    .select(\"Title\", \"count\")\n",
    "    .orderBy('count', ascending=0)\n",
    "    .show()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extra: Find the best rated movies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Continuing from above, we now wish to find the top five highest rated films.\n",
    "\n",
    "The best films are defined as those that have both the highest average rating **then** the most votes.\n",
    "\n",
    "\n",
    "* `groupBy` MovieID\n",
    "* use `.agg()` to explictly aggregate both the mean and count for Rating\n",
    "* `orderBy` both the average and count (orderBy takes multiple columns and a list for `ascending`)\n",
    "* `join` with the items on MovieID, and `select`, as above\n",
    "* `filter` so each film has a rating count of at least, eg., 100\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import mean, count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "tags": [
     "solution"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------------------+---+\n",
      "|               Title|                Er| Nr|\n",
      "+--------------------+------------------+---+\n",
      "|Close Shave, A (1...| 4.491071428571429|112|\n",
      "|Schindler's List ...| 4.466442953020135|298|\n",
      "|Wrong Trousers, T...| 4.466101694915254|118|\n",
      "|   Casablanca (1942)|  4.45679012345679|243|\n",
      "|Shawshank Redempt...| 4.445229681978798|283|\n",
      "|  Rear Window (1954)|4.3875598086124405|209|\n",
      "|Usual Suspects, T...| 4.385767790262173|267|\n",
      "|    Star Wars (1977)|4.3584905660377355|583|\n",
      "| 12 Angry Men (1957)|             4.344|125|\n",
      "| Citizen Kane (1941)| 4.292929292929293|198|\n",
      "+--------------------+------------------+---+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "results = (\n",
    "    dfu.select('MovieID', 'Rating')\n",
    "      .groupBy('MovieID')\n",
    "      .agg(\n",
    "        mean('Rating').alias('Er'),\n",
    "        count('Rating').alias('Nr')\n",
    "      )\n",
    ")\n",
    "\n",
    "(results\n",
    "    .join(dfi, results['MovieID'] == dfi['MovieID'])\n",
    "    .select(\"Title\", \"Er\", \"Nr\")\n",
    "    .filter(results[\"Nr\"] > 100)\n",
    "    .orderBy('Er', 'Nr', ascending=[0,0])\n",
    "    .show(10)\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
